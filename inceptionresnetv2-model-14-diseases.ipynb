{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Found GPU at: /device:GPU:0\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nfrom itertools import chain\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, average_precision_score\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"os.environ['CUDA_VISIBLE_DEVICES'] = '0'","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = '../input/data/'\nimage_size = 256\nbatch_size = 32","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Data preprocessing","metadata":{}},{"cell_type":"markdown","source":"### Preprocessing Metadata","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(f'{DATA_DIR}Data_Entry_2017.csv')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_image_paths = {os.path.basename(x): x for x in glob(os.path.join(DATA_DIR, 'images*', '*', '*.png'))}","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df['path'] = df['Image Index'].map(data_image_paths.get)","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df['Finding Labels'] = df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"labels = np.unique(list(chain(*df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nlabels = [x for x in labels if len(x) > 0]","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['Atelectasis',\n 'Cardiomegaly',\n 'Consolidation',\n 'Edema',\n 'Effusion',\n 'Emphysema',\n 'Fibrosis',\n 'Hernia',\n 'Infiltration',\n 'Mass',\n 'Nodule',\n 'Pleural_Thickening',\n 'Pneumonia',\n 'Pneumothorax']"},"metadata":{}}]},{"cell_type":"code","source":"for label in labels:\n    if len(label) > 1:\n        df[label] = df['Finding Labels'].map(lambda finding: 1.0 if label in finding else 0.0)","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"        Image Index          Finding Labels  Follow-up #  Patient ID  \\\n0  00000001_000.png            Cardiomegaly            0           1   \n1  00000001_001.png  Cardiomegaly|Emphysema            1           1   \n2  00000001_002.png   Cardiomegaly|Effusion            2           1   \n3  00000002_000.png                                    0           2   \n4  00000003_000.png                  Hernia            0           3   \n\n   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n0           58              M            PA                 2682     2749   \n1           58              M            PA                 2894     2729   \n2           58              M            PA                 2500     2048   \n3           81              M            PA                 2500     2048   \n4           81              F            PA                 2582     2991   \n\n   OriginalImagePixelSpacing[x  ...  Effusion  Emphysema Fibrosis  Hernia  \\\n0                        0.143  ...       0.0        0.0      0.0     0.0   \n1                        0.143  ...       0.0        1.0      0.0     0.0   \n2                        0.168  ...       1.0        0.0      0.0     0.0   \n3                        0.171  ...       0.0        0.0      0.0     0.0   \n4                        0.143  ...       0.0        0.0      0.0     1.0   \n\n   Infiltration  Mass  Nodule  Pleural_Thickening  Pneumonia  Pneumothorax  \n0           0.0   0.0     0.0                 0.0        0.0           0.0  \n1           0.0   0.0     0.0                 0.0        0.0           0.0  \n2           0.0   0.0     0.0                 0.0        0.0           0.0  \n3           0.0   0.0     0.0                 0.0        0.0           0.0  \n4           0.0   0.0     0.0                 0.0        0.0           0.0  \n\n[5 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image Index</th>\n      <th>Finding Labels</th>\n      <th>Follow-up #</th>\n      <th>Patient ID</th>\n      <th>Patient Age</th>\n      <th>Patient Gender</th>\n      <th>View Position</th>\n      <th>OriginalImage[Width</th>\n      <th>Height]</th>\n      <th>OriginalImagePixelSpacing[x</th>\n      <th>...</th>\n      <th>Effusion</th>\n      <th>Emphysema</th>\n      <th>Fibrosis</th>\n      <th>Hernia</th>\n      <th>Infiltration</th>\n      <th>Mass</th>\n      <th>Nodule</th>\n      <th>Pleural_Thickening</th>\n      <th>Pneumonia</th>\n      <th>Pneumothorax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000001_000.png</td>\n      <td>Cardiomegaly</td>\n      <td>0</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2682</td>\n      <td>2749</td>\n      <td>0.143</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000001_001.png</td>\n      <td>Cardiomegaly|Emphysema</td>\n      <td>1</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2894</td>\n      <td>2729</td>\n      <td>0.143</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000001_002.png</td>\n      <td>Cardiomegaly|Effusion</td>\n      <td>2</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.168</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000002_000.png</td>\n      <td></td>\n      <td>0</td>\n      <td>2</td>\n      <td>81</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.171</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000003_000.png</td>\n      <td>Hernia</td>\n      <td>0</td>\n      <td>3</td>\n      <td>81</td>\n      <td>F</td>\n      <td>PA</td>\n      <td>2582</td>\n      <td>2991</td>\n      <td>0.143</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 27 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"labels = [label for label in labels if df[label].sum() > 1000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, valid_df = train_test_split(df, test_size=0.20, random_state=2018, stratify=df['Finding Labels'].map(lambda x: x[:4]))","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_df['labels'] = train_df.apply(lambda x: x['Finding Labels'].split('|'), axis=1)\nvalid_df['labels'] = valid_df.apply(lambda x: x['Finding Labels'].split('|'), axis=1)","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Define DataGenerator","metadata":{}},{"cell_type":"code","source":"core_idg = ImageDataGenerator(rescale=1 / 255,\n                                  samplewise_center=True,\n                                  samplewise_std_normalization=True,\n                                  horizontal_flip=True,\n                                  vertical_flip=False,\n                                  height_shift_range=0.05,\n                                  width_shift_range=0.1,\n                                  rotation_range=5,\n                                  shear_range=0.1,\n                                  fill_mode='reflect',\n                                  zoom_range=0.15)\n\ntrain_gen = core_idg.flow_from_dataframe(dataframe=train_df,\n                                             directory=None,\n                                             x_col='path',\n                                             y_col='labels',\n                                             class_mode='categorical',\n                                             batch_size=batch_size,\n                                             classes=labels,\n                                             target_size=(image_size, image_size))\n\nvalid_gen = core_idg.flow_from_dataframe(dataframe=valid_df,\n                                             directory=None,\n                                             x_col='path',\n                                             y_col='labels',\n                                             class_mode='categorical',\n                                             batch_size=batch_size,\n                                             classes=labels,\n                                             target_size=(image_size, image_size))\n\ntest_X, test_Y = next(core_idg.flow_from_dataframe(dataframe=valid_df,\n                                                       directory=None,\n                                                       x_col='path',\n                                                       y_col='labels',\n                                                       class_mode='categorical',\n                                                       batch_size=1024,\n                                                       classes=labels,\n                                                       target_size=(image_size, image_size)))","metadata":{"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Found 41407 validated image filenames belonging to 14 classes.\nFound 10352 validated image filenames belonging to 14 classes.\nFound 10352 validated image filenames belonging to 14 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Create model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.densenet import DenseNet121\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.nasnet import NASNetMobile\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n\nbase_model = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\nx = base_model.output\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\noutput = tf.keras.layers.Dense(len(labels), activation=\"softmax\")(x)\nmodel = tf.keras.Model(base_model.input, output)\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n219062272/219055592 [==============================] - 4s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_callbacks(model_name):\n    callbacks = []\n    tensor_board = tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0)\n    callbacks.append(tensor_board)\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=f'model.{model_name}.h5',\n        verbose=1,\n        save_best_only=True)\n    # erly = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n    callbacks.append(checkpoint)\n    # callbacks.append(erly)\n    return callbacks","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"code","source":"callbacks = get_callbacks('inceptionresnetv2')\nmodel.fit(train_gen,\n              steps_per_epoch=128,\n              validation_data=(test_X, test_Y),\n              epochs=100,\n              callbacks=callbacks)","metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Train for 128 steps, validate on 1024 samples\nEpoch 1/100\n127/128 [============================>.] - ETA: 1s - loss: 0.3202 - accuracy: 0.8874\nEpoch 00001: val_loss improved from inf to 0.44087, saving model to model.inceptionresnetv2.h5\n128/128 [==============================] - 238s 2s/step - loss: 0.3200 - accuracy: 0.8874 - val_loss: 0.4409 - val_accuracy: 0.8867\nEpoch 2/100\n127/128 [============================>.] - ETA: 1s - loss: 0.3055 - accuracy: 0.8879\nEpoch 00002: val_loss did not improve from 0.44087\n128/128 [==============================] - 192s 2s/step - loss: 0.3055 - accuracy: 0.8878 - val_loss: 0.5202 - val_accuracy: 0.8764\nEpoch 3/100\n127/128 [============================>.] - ETA: 1s - loss: 0.3037 - accuracy: 0.8870\nEpoch 00003: val_loss improved from 0.44087 to 0.35086, saving model to model.inceptionresnetv2.h5\n128/128 [==============================] - 191s 1s/step - loss: 0.3037 - accuracy: 0.8870 - val_loss: 0.3509 - val_accuracy: 0.8855\nEpoch 4/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2973 - accuracy: 0.8877\nEpoch 00004: val_loss improved from 0.35086 to 0.34284, saving model to model.inceptionresnetv2.h5\n128/128 [==============================] - 191s 1s/step - loss: 0.2973 - accuracy: 0.8877 - val_loss: 0.3428 - val_accuracy: 0.8857\nEpoch 5/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2908 - accuracy: 0.8897\nEpoch 00005: val_loss did not improve from 0.34284\n128/128 [==============================] - 184s 1s/step - loss: 0.2905 - accuracy: 0.8898 - val_loss: 0.3622 - val_accuracy: 0.8845\nEpoch 6/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2872 - accuracy: 0.8894\nEpoch 00006: val_loss did not improve from 0.34284\n128/128 [==============================] - 183s 1s/step - loss: 0.2868 - accuracy: 0.8895 - val_loss: 0.3616 - val_accuracy: 0.8782\nEpoch 7/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2875 - accuracy: 0.8896\nEpoch 00007: val_loss improved from 0.34284 to 0.31585, saving model to model.inceptionresnetv2.h5\n128/128 [==============================] - 184s 1s/step - loss: 0.2872 - accuracy: 0.8897 - val_loss: 0.3159 - val_accuracy: 0.8884\nEpoch 8/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2852 - accuracy: 0.8903\nEpoch 00008: val_loss improved from 0.31585 to 0.30040, saving model to model.inceptionresnetv2.h5\n128/128 [==============================] - 186s 1s/step - loss: 0.2857 - accuracy: 0.8902 - val_loss: 0.3004 - val_accuracy: 0.8859\nEpoch 9/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2826 - accuracy: 0.8901\nEpoch 00009: val_loss did not improve from 0.30040\n128/128 [==============================] - 178s 1s/step - loss: 0.2829 - accuracy: 0.8900 - val_loss: 0.3041 - val_accuracy: 0.8869\nEpoch 10/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2845 - accuracy: 0.8897\nEpoch 00010: val_loss improved from 0.30040 to 0.29833, saving model to model.inceptionresnetv2.h5\n128/128 [==============================] - 184s 1s/step - loss: 0.2848 - accuracy: 0.8896 - val_loss: 0.2983 - val_accuracy: 0.8872\nEpoch 11/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2780 - accuracy: 0.8920\nEpoch 00011: val_loss improved from 0.29833 to 0.29725, saving model to model.inceptionresnetv2.h5\n128/128 [==============================] - 182s 1s/step - loss: 0.2782 - accuracy: 0.8920 - val_loss: 0.2973 - val_accuracy: 0.8876\nEpoch 12/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2832 - accuracy: 0.8902\nEpoch 00012: val_loss did not improve from 0.29725\n128/128 [==============================] - 178s 1s/step - loss: 0.2831 - accuracy: 0.8902 - val_loss: 0.3157 - val_accuracy: 0.8846\nEpoch 13/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2816 - accuracy: 0.8902\nEpoch 00013: val_loss did not improve from 0.29725\n128/128 [==============================] - 174s 1s/step - loss: 0.2817 - accuracy: 0.8902 - val_loss: 0.3035 - val_accuracy: 0.8878\nEpoch 14/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2785 - accuracy: 0.8912\nEpoch 00014: val_loss improved from 0.29725 to 0.29146, saving model to model.inceptionresnetv2.h5\n128/128 [==============================] - 173s 1s/step - loss: 0.2783 - accuracy: 0.8911 - val_loss: 0.2915 - val_accuracy: 0.8896\nEpoch 15/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2796 - accuracy: 0.8902\nEpoch 00015: val_loss did not improve from 0.29146\n128/128 [==============================] - 175s 1s/step - loss: 0.2795 - accuracy: 0.8902 - val_loss: 0.3061 - val_accuracy: 0.8869\nEpoch 16/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2728 - accuracy: 0.8932\nEpoch 00016: val_loss did not improve from 0.29146\n128/128 [==============================] - 174s 1s/step - loss: 0.2728 - accuracy: 0.8932 - val_loss: 0.2922 - val_accuracy: 0.8891\nEpoch 17/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2768 - accuracy: 0.8919\nEpoch 00017: val_loss did not improve from 0.29146\n128/128 [==============================] - 176s 1s/step - loss: 0.2771 - accuracy: 0.8918 - val_loss: 0.2925 - val_accuracy: 0.8892\nEpoch 18/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2750 - accuracy: 0.8921\nEpoch 00018: val_loss improved from 0.29146 to 0.28648, saving model to model.inceptionresnetv2.h5\n128/128 [==============================] - 180s 1s/step - loss: 0.2754 - accuracy: 0.8920 - val_loss: 0.2865 - val_accuracy: 0.8896\nEpoch 19/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2780 - accuracy: 0.8907\nEpoch 00019: val_loss improved from 0.28648 to 0.28151, saving model to model.inceptionresnetv2.h5\n128/128 [==============================] - 176s 1s/step - loss: 0.2779 - accuracy: 0.8907 - val_loss: 0.2815 - val_accuracy: 0.8901\nEpoch 20/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2713 - accuracy: 0.8932\nEpoch 00020: val_loss did not improve from 0.28151\n128/128 [==============================] - 172s 1s/step - loss: 0.2712 - accuracy: 0.8932 - val_loss: 0.2844 - val_accuracy: 0.8905\nEpoch 21/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2764 - accuracy: 0.8906\nEpoch 00021: val_loss did not improve from 0.28151\n128/128 [==============================] - 175s 1s/step - loss: 0.2764 - accuracy: 0.8906 - val_loss: 0.2840 - val_accuracy: 0.8897\nEpoch 22/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2674 - accuracy: 0.8933\nEpoch 00022: val_loss did not improve from 0.28151\n128/128 [==============================] - 173s 1s/step - loss: 0.2677 - accuracy: 0.8933 - val_loss: 0.2973 - val_accuracy: 0.8878\nEpoch 23/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2666 - accuracy: 0.8945\nEpoch 00023: val_loss improved from 0.28151 to 0.28127, saving model to model.inceptionresnetv2.h5\n128/128 [==============================] - 177s 1s/step - loss: 0.2666 - accuracy: 0.8945 - val_loss: 0.2813 - val_accuracy: 0.8920\nEpoch 24/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2727 - accuracy: 0.8923\nEpoch 00024: val_loss did not improve from 0.28127\n128/128 [==============================] - 173s 1s/step - loss: 0.2730 - accuracy: 0.8924 - val_loss: 0.2873 - val_accuracy: 0.8885\nEpoch 25/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2759 - accuracy: 0.8917\nEpoch 00025: val_loss did not improve from 0.28127\n128/128 [==============================] - 163s 1s/step - loss: 0.2762 - accuracy: 0.8917 - val_loss: 0.3123 - val_accuracy: 0.8908\nEpoch 26/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2783 - accuracy: 0.8911\nEpoch 00026: val_loss did not improve from 0.28127\n128/128 [==============================] - 164s 1s/step - loss: 0.2782 - accuracy: 0.8911 - val_loss: 0.2933 - val_accuracy: 0.8887\nEpoch 27/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2760 - accuracy: 0.8910\nEpoch 00027: val_loss did not improve from 0.28127\n128/128 [==============================] - 168s 1s/step - loss: 0.2756 - accuracy: 0.8911 - val_loss: 0.2895 - val_accuracy: 0.8892\nEpoch 28/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2698 - accuracy: 0.8932\nEpoch 00028: val_loss did not improve from 0.28127\n128/128 [==============================] - 172s 1s/step - loss: 0.2697 - accuracy: 0.8933 - val_loss: 0.2913 - val_accuracy: 0.8894\nEpoch 29/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2706 - accuracy: 0.8936\nEpoch 00029: val_loss did not improve from 0.28127\n128/128 [==============================] - 174s 1s/step - loss: 0.2707 - accuracy: 0.8936 - val_loss: 0.3107 - val_accuracy: 0.8882\nEpoch 30/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2697 - accuracy: 0.8922\nEpoch 00030: val_loss improved from 0.28127 to 0.27967, saving model to model.inceptionresnetv2.h5\n128/128 [==============================] - 171s 1s/step - loss: 0.2696 - accuracy: 0.8923 - val_loss: 0.2797 - val_accuracy: 0.8933\nEpoch 31/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2708 - accuracy: 0.8924\nEpoch 00031: val_loss did not improve from 0.27967\n128/128 [==============================] - 173s 1s/step - loss: 0.2707 - accuracy: 0.8926 - val_loss: 0.7070 - val_accuracy: 0.8800\nEpoch 32/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2678 - accuracy: 0.8934\nEpoch 00032: val_loss did not improve from 0.27967\n128/128 [==============================] - 174s 1s/step - loss: 0.2673 - accuracy: 0.8936 - val_loss: 0.2838 - val_accuracy: 0.8915\nEpoch 33/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2698 - accuracy: 0.8930\nEpoch 00033: val_loss did not improve from 0.27967\n128/128 [==============================] - 175s 1s/step - loss: 0.2697 - accuracy: 0.8931 - val_loss: 0.2929 - val_accuracy: 0.8889\nEpoch 34/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2673 - accuracy: 0.8933\nEpoch 00034: val_loss did not improve from 0.27967\n128/128 [==============================] - 174s 1s/step - loss: 0.2678 - accuracy: 0.8931 - val_loss: 0.3597 - val_accuracy: 0.8868\nEpoch 35/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2706 - accuracy: 0.8931\nEpoch 00035: val_loss did not improve from 0.27967\n128/128 [==============================] - 174s 1s/step - loss: 0.2704 - accuracy: 0.8931 - val_loss: 0.2848 - val_accuracy: 0.8898\nEpoch 36/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2651 - accuracy: 0.8943\nEpoch 00036: val_loss improved from 0.27967 to 0.27851, saving model to model.inceptionresnetv2.h5\n128/128 [==============================] - 178s 1s/step - loss: 0.2662 - accuracy: 0.8941 - val_loss: 0.2785 - val_accuracy: 0.8918\nEpoch 37/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2680 - accuracy: 0.8948\nEpoch 00037: val_loss did not improve from 0.27851\n128/128 [==============================] - 174s 1s/step - loss: 0.2683 - accuracy: 0.8948 - val_loss: 0.2936 - val_accuracy: 0.8927\nEpoch 38/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2704 - accuracy: 0.8928\nEpoch 00038: val_loss did not improve from 0.27851\n128/128 [==============================] - 183s 1s/step - loss: 0.2701 - accuracy: 0.8929 - val_loss: 0.3014 - val_accuracy: 0.8892\nEpoch 39/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2685 - accuracy: 0.8937\nEpoch 00039: val_loss did not improve from 0.27851\n128/128 [==============================] - 176s 1s/step - loss: 0.2685 - accuracy: 0.8937 - val_loss: 0.3101 - val_accuracy: 0.8913\nEpoch 40/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2683 - accuracy: 0.8943\nEpoch 00040: val_loss did not improve from 0.27851\n128/128 [==============================] - 170s 1s/step - loss: 0.2686 - accuracy: 0.8943 - val_loss: 0.3984 - val_accuracy: 0.8874\nEpoch 41/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2608 - accuracy: 0.8956\nEpoch 00041: val_loss did not improve from 0.27851\n128/128 [==============================] - 172s 1s/step - loss: 0.2611 - accuracy: 0.8955 - val_loss: 0.3032 - val_accuracy: 0.8915\nEpoch 42/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2706 - accuracy: 0.8921\nEpoch 00042: val_loss did not improve from 0.27851\n128/128 [==============================] - 171s 1s/step - loss: 0.2707 - accuracy: 0.8920 - val_loss: 0.2830 - val_accuracy: 0.8908\nEpoch 43/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2623 - accuracy: 0.8960\nEpoch 00043: val_loss did not improve from 0.27851\n128/128 [==============================] - 175s 1s/step - loss: 0.2623 - accuracy: 0.8961 - val_loss: 0.2926 - val_accuracy: 0.8902\nEpoch 44/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2694 - accuracy: 0.8925\nEpoch 00044: val_loss did not improve from 0.27851\n128/128 [==============================] - 173s 1s/step - loss: 0.2693 - accuracy: 0.8925 - val_loss: 0.2829 - val_accuracy: 0.8912\nEpoch 45/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2614 - accuracy: 0.8940\nEpoch 00045: val_loss improved from 0.27851 to 0.27809, saving model to model.inceptionresnetv2.h5\n128/128 [==============================] - 173s 1s/step - loss: 0.2616 - accuracy: 0.8940 - val_loss: 0.2781 - val_accuracy: 0.8926\nEpoch 46/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2667 - accuracy: 0.8935\nEpoch 00046: val_loss did not improve from 0.27809\n128/128 [==============================] - 172s 1s/step - loss: 0.2669 - accuracy: 0.8934 - val_loss: 0.2817 - val_accuracy: 0.8923\nEpoch 47/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2637 - accuracy: 0.8952\nEpoch 00047: val_loss did not improve from 0.27809\n128/128 [==============================] - 174s 1s/step - loss: 0.2638 - accuracy: 0.8950 - val_loss: 0.2819 - val_accuracy: 0.8908\nEpoch 48/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2666 - accuracy: 0.8945\nEpoch 00048: val_loss did not improve from 0.27809\n128/128 [==============================] - 179s 1s/step - loss: 0.2667 - accuracy: 0.8945 - val_loss: 0.5843 - val_accuracy: 0.8769\nEpoch 49/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2635 - accuracy: 0.8945\nEpoch 00049: val_loss did not improve from 0.27809\n128/128 [==============================] - 173s 1s/step - loss: 0.2632 - accuracy: 0.8946 - val_loss: 0.2927 - val_accuracy: 0.8906\nEpoch 50/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2620 - accuracy: 0.8965\nEpoch 00050: val_loss did not improve from 0.27809\n128/128 [==============================] - 185s 1s/step - loss: 0.2625 - accuracy: 0.8963 - val_loss: 0.2838 - val_accuracy: 0.8910\nEpoch 51/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2661 - accuracy: 0.8944\nEpoch 00051: val_loss did not improve from 0.27809\n128/128 [==============================] - 176s 1s/step - loss: 0.2658 - accuracy: 0.8944 - val_loss: 0.2867 - val_accuracy: 0.8926\nEpoch 52/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2679 - accuracy: 0.8938\nEpoch 00052: val_loss did not improve from 0.27809\n128/128 [==============================] - 172s 1s/step - loss: 0.2679 - accuracy: 0.8938 - val_loss: 0.2837 - val_accuracy: 0.8910\nEpoch 53/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2648 - accuracy: 0.8940\nEpoch 00053: val_loss did not improve from 0.27809\n128/128 [==============================] - 172s 1s/step - loss: 0.2647 - accuracy: 0.8940 - val_loss: 0.2803 - val_accuracy: 0.8895\nEpoch 54/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2639 - accuracy: 0.8953\nEpoch 00054: val_loss did not improve from 0.27809\n128/128 [==============================] - 171s 1s/step - loss: 0.2637 - accuracy: 0.8952 - val_loss: 0.3273 - val_accuracy: 0.8871\nEpoch 55/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2641 - accuracy: 0.8946\nEpoch 00055: val_loss did not improve from 0.27809\n128/128 [==============================] - 172s 1s/step - loss: 0.2639 - accuracy: 0.8945 - val_loss: 0.3048 - val_accuracy: 0.8878\nEpoch 56/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2593 - accuracy: 0.8975\nEpoch 00056: val_loss improved from 0.27809 to 0.27438, saving model to model.inceptionresnetv2.h5\n128/128 [==============================] - 175s 1s/step - loss: 0.2593 - accuracy: 0.8975 - val_loss: 0.2744 - val_accuracy: 0.8903\nEpoch 57/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2622 - accuracy: 0.8961\nEpoch 00057: val_loss did not improve from 0.27438\n128/128 [==============================] - 173s 1s/step - loss: 0.2622 - accuracy: 0.8960 - val_loss: 0.2891 - val_accuracy: 0.8899\nEpoch 58/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2627 - accuracy: 0.8951\nEpoch 00058: val_loss did not improve from 0.27438\n128/128 [==============================] - 175s 1s/step - loss: 0.2625 - accuracy: 0.8952 - val_loss: 0.2814 - val_accuracy: 0.8907\nEpoch 59/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2612 - accuracy: 0.8954\nEpoch 00059: val_loss did not improve from 0.27438\n128/128 [==============================] - 168s 1s/step - loss: 0.2616 - accuracy: 0.8953 - val_loss: 0.3165 - val_accuracy: 0.8892\nEpoch 60/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2616 - accuracy: 0.8949\nEpoch 00060: val_loss did not improve from 0.27438\n128/128 [==============================] - 164s 1s/step - loss: 0.2616 - accuracy: 0.8949 - val_loss: 0.2823 - val_accuracy: 0.8917\nEpoch 61/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2587 - accuracy: 0.8960\nEpoch 00061: val_loss did not improve from 0.27438\n128/128 [==============================] - 174s 1s/step - loss: 0.2588 - accuracy: 0.8959 - val_loss: 0.2801 - val_accuracy: 0.8913\nEpoch 62/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2613 - accuracy: 0.8953\nEpoch 00062: val_loss did not improve from 0.27438\n128/128 [==============================] - 174s 1s/step - loss: 0.2613 - accuracy: 0.8954 - val_loss: 0.2781 - val_accuracy: 0.8938\nEpoch 63/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2621 - accuracy: 0.8951\nEpoch 00063: val_loss did not improve from 0.27438\n128/128 [==============================] - 169s 1s/step - loss: 0.2619 - accuracy: 0.8951 - val_loss: 0.2989 - val_accuracy: 0.8899\nEpoch 64/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2567 - accuracy: 0.8970\nEpoch 00064: val_loss did not improve from 0.27438\n128/128 [==============================] - 175s 1s/step - loss: 0.2569 - accuracy: 0.8969 - val_loss: 0.2820 - val_accuracy: 0.8896\nEpoch 65/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2604 - accuracy: 0.8962\nEpoch 00065: val_loss did not improve from 0.27438\n128/128 [==============================] - 165s 1s/step - loss: 0.2604 - accuracy: 0.8962 - val_loss: 0.2842 - val_accuracy: 0.8913\nEpoch 66/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2575 - accuracy: 0.8967\nEpoch 00066: val_loss did not improve from 0.27438\n128/128 [==============================] - 170s 1s/step - loss: 0.2575 - accuracy: 0.8968 - val_loss: 0.2976 - val_accuracy: 0.8913\nEpoch 67/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2613 - accuracy: 0.8946\nEpoch 00067: val_loss did not improve from 0.27438\n128/128 [==============================] - 168s 1s/step - loss: 0.2611 - accuracy: 0.8946 - val_loss: 0.2924 - val_accuracy: 0.8931\nEpoch 68/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2613 - accuracy: 0.8952\nEpoch 00068: val_loss did not improve from 0.27438\n128/128 [==============================] - 169s 1s/step - loss: 0.2615 - accuracy: 0.8952 - val_loss: 0.2838 - val_accuracy: 0.8908\nEpoch 69/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2594 - accuracy: 0.8970\nEpoch 00069: val_loss did not improve from 0.27438\n128/128 [==============================] - 174s 1s/step - loss: 0.2593 - accuracy: 0.8971 - val_loss: 0.2798 - val_accuracy: 0.8913\nEpoch 70/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2624 - accuracy: 0.8946\nEpoch 00070: val_loss did not improve from 0.27438\n128/128 [==============================] - 176s 1s/step - loss: 0.2623 - accuracy: 0.8946 - val_loss: 0.2798 - val_accuracy: 0.8927\nEpoch 71/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2594 - accuracy: 0.8966\nEpoch 00071: val_loss did not improve from 0.27438\n128/128 [==============================] - 170s 1s/step - loss: 0.2595 - accuracy: 0.8966 - val_loss: 0.2759 - val_accuracy: 0.8888\nEpoch 72/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2650 - accuracy: 0.8944\nEpoch 00072: val_loss did not improve from 0.27438\n128/128 [==============================] - 173s 1s/step - loss: 0.2652 - accuracy: 0.8943 - val_loss: 0.2880 - val_accuracy: 0.8910\nEpoch 73/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2574 - accuracy: 0.8967\nEpoch 00073: val_loss did not improve from 0.27438\n128/128 [==============================] - 172s 1s/step - loss: 0.2575 - accuracy: 0.8967 - val_loss: 0.2949 - val_accuracy: 0.8879\nEpoch 74/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2611 - accuracy: 0.8960\nEpoch 00074: val_loss did not improve from 0.27438\n128/128 [==============================] - 180s 1s/step - loss: 0.2612 - accuracy: 0.8960 - val_loss: 0.2821 - val_accuracy: 0.8904\nEpoch 75/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2587 - accuracy: 0.8959\nEpoch 00075: val_loss did not improve from 0.27438\n128/128 [==============================] - 176s 1s/step - loss: 0.2592 - accuracy: 0.8957 - val_loss: 0.2922 - val_accuracy: 0.8892\nEpoch 76/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2599 - accuracy: 0.8961\nEpoch 00076: val_loss did not improve from 0.27438\n128/128 [==============================] - 175s 1s/step - loss: 0.2600 - accuracy: 0.8961 - val_loss: 0.2962 - val_accuracy: 0.8901\nEpoch 77/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2568 - accuracy: 0.8970\nEpoch 00077: val_loss did not improve from 0.27438\n128/128 [==============================] - 171s 1s/step - loss: 0.2567 - accuracy: 0.8971 - val_loss: 0.3032 - val_accuracy: 0.8910\nEpoch 78/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2589 - accuracy: 0.8949\nEpoch 00078: val_loss did not improve from 0.27438\n128/128 [==============================] - 169s 1s/step - loss: 0.2591 - accuracy: 0.8948 - val_loss: 0.2819 - val_accuracy: 0.8910\nEpoch 79/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2607 - accuracy: 0.8939\nEpoch 00079: val_loss did not improve from 0.27438\n128/128 [==============================] - 176s 1s/step - loss: 0.2608 - accuracy: 0.8939 - val_loss: 0.2981 - val_accuracy: 0.8920\nEpoch 80/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2534 - accuracy: 0.8989\nEpoch 00080: val_loss did not improve from 0.27438\n128/128 [==============================] - 163s 1s/step - loss: 0.2532 - accuracy: 0.8989 - val_loss: 0.2754 - val_accuracy: 0.8920\nEpoch 81/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2585 - accuracy: 0.8961\nEpoch 00081: val_loss did not improve from 0.27438\n128/128 [==============================] - 162s 1s/step - loss: 0.2584 - accuracy: 0.8960 - val_loss: 0.2901 - val_accuracy: 0.8918\nEpoch 82/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2546 - accuracy: 0.8969\nEpoch 00082: val_loss did not improve from 0.27438\n128/128 [==============================] - 173s 1s/step - loss: 0.2548 - accuracy: 0.8968 - val_loss: 0.2871 - val_accuracy: 0.8931\nEpoch 83/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2577 - accuracy: 0.8966\nEpoch 00083: val_loss did not improve from 0.27438\n128/128 [==============================] - 175s 1s/step - loss: 0.2579 - accuracy: 0.8966 - val_loss: 0.2778 - val_accuracy: 0.8896\nEpoch 84/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2499 - accuracy: 0.8998\nEpoch 00084: val_loss did not improve from 0.27438\n128/128 [==============================] - 171s 1s/step - loss: 0.2497 - accuracy: 0.8998 - val_loss: 0.3019 - val_accuracy: 0.8912\nEpoch 85/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2573 - accuracy: 0.8972\nEpoch 00085: val_loss did not improve from 0.27438\n128/128 [==============================] - 179s 1s/step - loss: 0.2575 - accuracy: 0.8970 - val_loss: 0.3291 - val_accuracy: 0.8920\nEpoch 86/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2519 - accuracy: 0.8985\nEpoch 00086: val_loss did not improve from 0.27438\n128/128 [==============================] - 175s 1s/step - loss: 0.2517 - accuracy: 0.8986 - val_loss: 0.2949 - val_accuracy: 0.8904\nEpoch 87/100\n127/128 [============================>.] - ETA: 2s - loss: 0.2562 - accuracy: 0.8972\nEpoch 00087: val_loss did not improve from 0.27438\n128/128 [==============================] - 358s 3s/step - loss: 0.2562 - accuracy: 0.8971 - val_loss: 0.2799 - val_accuracy: 0.8940\nEpoch 88/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2574 - accuracy: 0.8957\nEpoch 00088: val_loss did not improve from 0.27438\n128/128 [==============================] - 209s 2s/step - loss: 0.2577 - accuracy: 0.8955 - val_loss: 0.2833 - val_accuracy: 0.8924\nEpoch 89/100\n127/128 [============================>.] - ETA: 2s - loss: 0.2602 - accuracy: 0.8964\nEpoch 00089: val_loss did not improve from 0.27438\n128/128 [==============================] - 269s 2s/step - loss: 0.2602 - accuracy: 0.8964 - val_loss: 0.2804 - val_accuracy: 0.8921\nEpoch 90/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2533 - accuracy: 0.8983\nEpoch 00090: val_loss did not improve from 0.27438\n128/128 [==============================] - 193s 2s/step - loss: 0.2533 - accuracy: 0.8984 - val_loss: 0.2977 - val_accuracy: 0.8881\nEpoch 91/100\n127/128 [============================>.] - ETA: 2s - loss: 0.2567 - accuracy: 0.8972\nEpoch 00091: val_loss did not improve from 0.27438\n128/128 [==============================] - 264s 2s/step - loss: 0.2568 - accuracy: 0.8971 - val_loss: 0.2763 - val_accuracy: 0.8913\nEpoch 92/100\n127/128 [============================>.] - ETA: 2s - loss: 0.2592 - accuracy: 0.8960\nEpoch 00092: val_loss did not improve from 0.27438\n128/128 [==============================] - 279s 2s/step - loss: 0.2593 - accuracy: 0.8960 - val_loss: 0.2816 - val_accuracy: 0.8903\nEpoch 93/100\n127/128 [============================>.] - ETA: 2s - loss: 0.2569 - accuracy: 0.8970\nEpoch 00093: val_loss did not improve from 0.27438\n128/128 [==============================] - 293s 2s/step - loss: 0.2568 - accuracy: 0.8969 - val_loss: 0.3097 - val_accuracy: 0.8866\nEpoch 94/100\n127/128 [============================>.] - ETA: 2s - loss: 0.2581 - accuracy: 0.8961\nEpoch 00094: val_loss did not improve from 0.27438\n128/128 [==============================] - 327s 3s/step - loss: 0.2581 - accuracy: 0.8961 - val_loss: 0.6812 - val_accuracy: 0.8779\nEpoch 95/100\n127/128 [============================>.] - ETA: 2s - loss: 0.2527 - accuracy: 0.8993\nEpoch 00095: val_loss did not improve from 0.27438\n128/128 [==============================] - 290s 2s/step - loss: 0.2529 - accuracy: 0.8991 - val_loss: 0.4028 - val_accuracy: 0.8896\nEpoch 96/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2583 - accuracy: 0.8958\nEpoch 00096: val_loss did not improve from 0.27438\n128/128 [==============================] - 172s 1s/step - loss: 0.2580 - accuracy: 0.8958 - val_loss: 0.2934 - val_accuracy: 0.8904\nEpoch 97/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2574 - accuracy: 0.8959\nEpoch 00097: val_loss did not improve from 0.27438\n128/128 [==============================] - 184s 1s/step - loss: 0.2572 - accuracy: 0.8960 - val_loss: 0.3529 - val_accuracy: 0.8883\nEpoch 98/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2550 - accuracy: 0.8980\nEpoch 00098: val_loss did not improve from 0.27438\n128/128 [==============================] - 186s 1s/step - loss: 0.2548 - accuracy: 0.8981 - val_loss: 0.2794 - val_accuracy: 0.8948\nEpoch 99/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2592 - accuracy: 0.8948\nEpoch 00099: val_loss did not improve from 0.27438\n128/128 [==============================] - 178s 1s/step - loss: 0.2591 - accuracy: 0.8948 - val_loss: 0.2874 - val_accuracy: 0.8927\nEpoch 100/100\n127/128 [============================>.] - ETA: 1s - loss: 0.2589 - accuracy: 0.8963\nEpoch 00100: val_loss did not improve from 0.27438\n128/128 [==============================] - 174s 1s/step - loss: 0.2594 - accuracy: 0.8961 - val_loss: 0.2836 - val_accuracy: 0.8901\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f7cd27f1110>"},"metadata":{}}]},{"cell_type":"code","source":"model.save('Inceptionmodel.hdf5')","metadata":{"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model.save('Inception_Model.h5')","metadata":{"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\ninception = tf.keras.models.load_model('Inception_model.h5')","metadata":{"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_X.shape","metadata":{"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(1024, 256, 256, 3)"},"metadata":{}}]},{"cell_type":"code","source":"sample_image = test_X[0]\nsample_image = sample_image.reshape((1, 256,256,3))\ny_pred = inception.predict(sample_image)","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# From Here trying to predict roc auc score","metadata":{}},{"cell_type":"code","source":"y_pred","metadata":{"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array([[0.20432581, 0.07241496, 0.02441477, 0.00288388, 0.04341677,\n        0.00486424, 0.01700941, 0.00156534, 0.4571745 , 0.02062774,\n        0.10504288, 0.01822759, 0.02369078, 0.00434129]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\nprint(y_pred)\n# auc scores\nauc_score1 = roc_auc_score(test_Y, y_pred[:,1], multi_class='ovr')\nprint(auc_score1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = OneVsRestClassifier(LinearSVC(random_state=0))\ny_score = inception.fit(X_train, y_train).decision_function(X_test)\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot of a ROC curve for a specific class\nfor i in range(n_classes):\n    plt.figure()\n    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\ntest_Y = np.argmax(test_Y, axis=-1)\ny_pred = np.argmax(y_pred, axis=-1)\nfpr_roc, tpr_roc, thresholds_roc = roc_curve(test_Y, y_pred)\nroc_auc = metrics.auc(fpr_roc, tpr_roc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('test binary accuracy = ',model.evaluate(test_X,test_Y, verbose=0)[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\ntitles_options = [(\"Confusion matrix, without normalization\", None),\n                  (\"Normalized confusion matrix\", 'true')]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(model.fit(train_gen, valid_gen), X_test, y_test,\n                                 display_labels=labels,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title)\n\n    print(title)\n    print(disp.confusion_matrix)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_X.shape\nsample_image = test_X[1]\nsample_image = sample_image.reshape((1, 256,256,3))\nx = inception.predict(sample_image)\ndef disease(arr):\n    for i in range(arr.size):\n        print(\"Disease:\",disease_name[i],\"Probability:\",arr[i])\n    \ndisease(x[0]) ","metadata":{"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Disease: Atelectasis Probability: 0.010536501\nDisease: Cardiomegaly Probability: 0.0019368976\nDisease: Effusion Probability: 0.0071056136\nDisease: Infiltration Probability: 0.0019988636\nDisease: Mass Probability: 0.028456708\nDisease: Nodule Probability: 0.0024924085\nDisease: Pneumonia Probability: 0.004790143\nDisease: Pneumothorax Probability: 0.00035487764\nDisease: Consolidation Probability: 0.030642252\nDisease: Edema Probability: 0.41488007\nDisease: Emphysema Probability: 0.47335756\nDisease: Fibrosis Probability: 0.011693604\nDisease: Pleural Thickening Probability: 0.0016613251\nDisease: Hernia Probability: 0.010093181\n","output_type":"stream"}]},{"cell_type":"code","source":"test_X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_image = test_X[0]\nsample_image = sample_image.reshape((1, 256,256,3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = model.predict(sample_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disease_name = [\"Atelectasis\",\"Cardiomegaly\",\"Effusion\",\"Infiltration\",\"Mass\",\"Nodule\",\"Pneumonia\",\"Pneumothorax\",\"Consolidation\",\"Edema\",\"Emphysema\",\"Fibrosis\",\"Pleural Thickening\",\"Hernia\"] ","metadata":{"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def disease(arr):\n    for i in range(arr.size):\n        print(\"Disease:\",disease_name[i],\"Probability:\",arr[i])\n    \ndisease(x[0])  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Code for prediction**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import cv2\nimg = cv2.imread('../input/data/images_008/images/00016051_010.png')\nwidth = int(img.shape[1]*0.250)\nheight = int(img.shape[0]*0.250)\nsample_image2 = cv2.resize(img, (width, height), interpolation = cv2.INTER_AREA)\nprint(sample_image2.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_image2 = sample_image2.reshape((1, 256, 256, 3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(sample_image2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disease_name = [\"Atelectasis\",\"Cardiomegaly\",\"Effusion\",\"Infiltration\",\"Mass\",\"Nodule\",\"Pneumonia\",\"Pneumothorax\",\"Consolidation\",\"Edema\",\"Emphysema\",\"Fibrosis\",\"Pleural Thickening\",\"Hernia\"] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def disease(arr):\n    max_val = arr[0]\n    for i in range(arr.size):\n        print(arr[i])\n        if arr[i] > max_val:\n            max_val = arr[i]\n            index = i\n    \n    print(\"Disease:\",disease_name[index],\"Probability:\",max_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disease(x[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction\nimport cv2\nimg = cv2.imread('../input/data/images_010/images/00020945_050.png')\nwidth = int(img.shape[1]*0.250)\nheight = int(img.shape[0]*0.250)\nsample_image2 = cv2.resize(img, (width, height), interpolation = cv2.INTER_AREA)\nprint(sample_image2.shape)\n\nsample_image2 = sample_image2.reshape((1, 256, 256, 3))\nx = model.predict(sample_image2)\n\nprint(x)\n\ndisease(x[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}